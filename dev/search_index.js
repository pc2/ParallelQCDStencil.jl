var documenterSearchIndex = {"docs":
[{"location":"references/exports/#All-Exports","page":"All Exports","title":"All Exports","text":"","category":"section"},{"location":"references/exports/#Index","page":"All Exports","title":"Index","text":"","category":"section"},{"location":"references/exports/","page":"All Exports","title":"All Exports","text":"Pages   = [\"exports.md\"]\nOrder   = [:function, :type]","category":"page"},{"location":"references/exports/#References","page":"All Exports","title":"References","text":"","category":"section"},{"location":"references/exports/","page":"All Exports","title":"All Exports","text":"Modules = [ParallelQCDStencil]\nPrivate = false","category":"page"},{"location":"references/exports/#ParallelQCDStencil.ComputationMode","page":"All Exports","title":"ParallelQCDStencil.ComputationMode","text":"Computation mode for selection between serial or parallel computation.\n\n\n\n\n\n","category":"type"},{"location":"references/exports/#ParallelQCDStencil.StencilPara","page":"All Exports","title":"ParallelQCDStencil.StencilPara","text":"Struct with default values\n\n\n\n\n\n","category":"type"},{"location":"references/exports/#ParallelQCDStencil.compute_stencil-Tuple{Any, Any, MPI.Comm, Int64, LocalGridNaive}","page":"All Exports","title":"ParallelQCDStencil.compute_stencil","text":"Stencil computation in parallel\n\n\n\n\n\n","category":"method"},{"location":"references/exports/#ParallelQCDStencil.compute_stencil-Tuple{Any, Any, Sequential}","page":"All Exports","title":"ParallelQCDStencil.compute_stencil","text":"Stencil computation in serial\n\n\n\n\n\n","category":"method"},{"location":"references/exports/#ParallelQCDStencil.get_site_link_indexes-Tuple{Any, Any}","page":"All Exports","title":"ParallelQCDStencil.get_site_link_indexes","text":"Computes link indexes associated with site(i)\n\n\n\n\n\n","category":"method"},{"location":"references/exports/#ParallelQCDStencil.linear_link_values_to_site_based_array-Tuple{Any, Any}","page":"All Exports","title":"ParallelQCDStencil.linear_link_values_to_site_based_array","text":"Converting vector of link data into site centric structure\n\n\n\n\n\n","category":"method"},{"location":"#ParallelQCDStencil.jl","page":"ParallelQCDStencil","title":"ParallelQCDStencil.jl","text":"","category":"section"},{"location":"#Installation","page":"ParallelQCDStencil","title":"Installation","text":"","category":"section"},{"location":"","page":"ParallelQCDStencil","title":"ParallelQCDStencil","text":"] add https://git.uni-paderborn.de/cs-hit/theses/2022_parab/qcd-stencil/ParallelQCDStencil.jl","category":"page"},{"location":"","page":"ParallelQCDStencil","title":"ParallelQCDStencil","text":"Note: The minimal required Julia version is 1.7.","category":"page"},{"location":"#Assumptions","page":"ParallelQCDStencil","title":"Assumptions","text":"","category":"section"},{"location":"","page":"ParallelQCDStencil","title":"ParallelQCDStencil","text":"Link matrices must be of the same type and size 3x3 (independent of dimension)\nFor parallel computation:\nInner grids must be square and of the same size.\nDivision of the global grid by inner grid length must be an integer.","category":"page"},{"location":"#Usage","page":"ParallelQCDStencil","title":"Usage","text":"","category":"section"},{"location":"","page":"ParallelQCDStencil","title":"ParallelQCDStencil","text":"julia> using ParallelQCDStencil","category":"page"},{"location":"#Input-parameters","page":"ParallelQCDStencil","title":"Input parameters","text":"","category":"section"},{"location":"","page":"ParallelQCDStencil","title":"ParallelQCDStencil","text":"We are using struct for passing around the parameters to the fuctions. It consists of :","category":"page"},{"location":"","page":"ParallelQCDStencil","title":"ParallelQCDStencil","text":"L = 5                           #number of lattices in per dimension\nN = L^D                         #number of sites\nNL = N * D                      #number of links\nLD = 3                          #link matrix length\nC1::T = 2                       #stencil constant \nC2::T = 3                       #stencil constant   \nIG = 2                          #inner grid length\nn_IG_d = Int(floor(L / IG))     #grids per dimension\nn_IG = n_IG_d^D                 #number of inner grids\nmaster_rank = 0                 #mpi master rank","category":"page"},{"location":"","page":"ParallelQCDStencil","title":"ParallelQCDStencil","text":"Struct instantiation :","category":"page"},{"location":"","page":"ParallelQCDStencil","title":"ParallelQCDStencil","text":"# 2D Sequential \np = StencilPara{Int64, 2}(L=4)\n\n# 2D Parallel \np = StencilPara{Int64, 2}(L=4, IG=2)\n\n# 4D Parallel \np = StencilPara{Int64, 4}(L=4)","category":"page"},{"location":"#Input-data","page":"ParallelQCDStencil","title":"Input data","text":"","category":"section"},{"location":"","page":"ParallelQCDStencil","title":"ParallelQCDStencil","text":"For stencil computation input can be: ","category":"page"},{"location":"","page":"ParallelQCDStencil","title":"ParallelQCDStencil","text":"Array:\ne.g. 2D array of size 360000","category":"page"},{"location":"","page":"ParallelQCDStencil","title":"ParallelQCDStencil","text":"    #generating random array data\n    random_array_data = [rand(ComplexF64, (3,3)) for i in 1:360000]","category":"page"},{"location":"","page":"ParallelQCDStencil","title":"ParallelQCDStencil","text":"HDF5 file: \nFile containing array with variable name \"data\" \ne.g. 2D array of size 600x600x2x3x3 ","category":"page"},{"location":"","page":"ParallelQCDStencil","title":"ParallelQCDStencil","text":"    #generating random HDF5 file data\n    using HDF5\n    fn = \"2d_l_600_cf64.h5\"\n    @unpack NL, master_rank, C1, C2, N, LD = p\n\n    v = rand(ComplexF64,(600,600,2,3,3));       \n    h5open(fn, \"w\") do f\n        write(f, \"data\", v) \n    end","category":"page"},{"location":"#D-Sequential-stencil-computation-with-array-input","page":"ParallelQCDStencil","title":"2D Sequential stencil computation with array input","text":"","category":"section"},{"location":"","page":"ParallelQCDStencil","title":"ParallelQCDStencil","text":"    using ParallelQCDStencil\n    using Parameters\n    using LinearAlgebra\n\n    p = StencilPara{Int64, 2}(L=10, master_rank=0)\n    @unpack NL, master_rank, C1, C2, N, LD = p\n    \n    rmat = rand(ComplexF64, (LD,LD))\n    \n    data = ParallelQCDStencil.linear_link_values_to_site_based_array(p, [rmat for i in 1:NL])\n      \n    total = compute_stencil(p, data, Sequential())\n    \n    println(\"total:$(total) serial\\n \")","category":"page"},{"location":"#D-Parallel-stencil-computation-with-array-input","page":"ParallelQCDStencil","title":"2D Parallel stencil computation with array input","text":"","category":"section"},{"location":"","page":"ParallelQCDStencil","title":"ParallelQCDStencil","text":"    using ParallelQCDStencil\n    using MPI\n    using Parameters\n    using LinearAlgebra\n    \n    p = StencilPara{Int64, 2}(L=10, IG=5, master_rank=1)\n    @unpack NL, master_rank, C1, C2, N = p\n    \n    MPI.Init()\n    comm = MPI.COMM_WORLD\n    rank = MPI.Comm_rank(comm)\n    \n    if (rank == master_rank)\n        data = ParallelQCDStencil.linear_link_values_to_site_based_array(p, [rand(ComplexF64, (3,3)) for i in 1:NL])\n    else\n        data = nothing\n    end\n    total = compute_stencil(p, data, comm, rank, LocalGridNaive())\n    \n    if (rank == master_rank)\n        println(\"total:$(total)\\n\")\n    end\n    MPI.Finalize()","category":"page"},{"location":"#D-Parallel-stencil-computation-with-HDF5-input","page":"ParallelQCDStencil","title":"2D Parallel stencil computation with HDF5 input","text":"","category":"section"},{"location":"","page":"ParallelQCDStencil","title":"ParallelQCDStencil","text":"    using ParallelQCDStencil\n    using MPI\n    using Parameters\n    using LinearAlgebra\n    using HDF5\n    \n    p = StencilPara{Int64, 2}(L=10, IG=5, master_rank=1)\n    @unpack NL, master_rank, C1, C2, N, L, IG = p\n    d = ParallelQCDStencil._get_d_val(p)\n    \n    MPI.Init()\n    comm = MPI.COMM_WORLD\n    rank = MPI.Comm_rank(comm)\n    \n    file = \"data/2d/test_files/2d_array_l_10_cf64.h5\"\n    total = compute_stencil(p, file, comm, rank, LocalGridNaive(); file=true)\n\n    if (rank == master_rank)\n        println(\"total:$(total)\\n\")\n    end\n    MPI.Finalize()","category":"page"},{"location":"#D-Sequential-stencil-computation-with-array-input-2","page":"ParallelQCDStencil","title":"4D Sequential stencil computation with array input","text":"","category":"section"},{"location":"","page":"ParallelQCDStencil","title":"ParallelQCDStencil","text":"    using ParallelQCDStencil\n    using Parameters\n    using LinearAlgebra\n\n    p = StencilPara{Int64, 4}(L=10, master_rank=0)\n    @unpack NL, master_rank, C1, C2, N, LD = p\n    \n    rmat = rand(ComplexF64, (LD,LD))\n    \n    data = ParallelQCDStencil.linear_link_values_to_site_based_array(p, [rmat for i in 1:NL])\n      \n    total = compute_stencil(p, data, Sequential())\n    \n    println(\"total:$(total) serial\\n \")","category":"page"},{"location":"#Code-execution","page":"ParallelQCDStencil","title":"Code execution","text":"","category":"section"},{"location":"","page":"ParallelQCDStencil","title":"ParallelQCDStencil","text":"The program can be launched using MPI command e.g:","category":"page"},{"location":"","page":"ParallelQCDStencil","title":"ParallelQCDStencil","text":"mpirun -n 4 julia --project basic_example.jl","category":"page"}]
}
